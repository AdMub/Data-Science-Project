# -*- coding: utf-8 -*-
"""Parkison's Disease Detection using SVM Classifier.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/11VasHcm2A92V_CV4M44kZ-qnz9m9oZG6

# **Parkinsons Data Set**

## **About Dataset**

###**Title: Parkinsons Disease Data Set**

## **Introduction**
**Parkinsons Disease** is a progressive nervous system disorder that affects movements leading to shaking, stiffness, and difficulty with walking, balance, and coordination.

Parkinson's symptom usually begin gradually and get worse over time.

###**Abstract: Oxford Parkinson's Disease Detection Dataset**

**Data Set Characteristics:** Multivariate

**Number of Instances:** 197

**Area:** Life

**Attribute Characteristics: Real**

Number of Attributes:** 23

**Date Donated:** 2008-06-26

**Associated Tasks:** Classification

**Missing Values? N/A**

##**Source:**

The dataset was created by Max Little of the University of Oxford, in
collaboration with the National Centre for Voice and Speech, Denver,
Colorado, who recorded the speech signals. The original study published the
feature extraction methods for general voice disorders.

##**Data Set Information:**

This dataset is composed of a range of biomedical voice measurements from
31 people, 23 with Parkinson's disease (PD). Each column in the table is a
particular voice measure, and each row corresponds one of 195 voice
recording from these individuals ("name" column). The main aim of the data
is to discriminate healthy people from those with PD, according to "status"
column which is set to 0 for healthy and 1 for PD.

The data is in ASCII CSV format. The rows of the CSV file contain an
instance corresponding to one voice recording. There are around six
recordings per patient, the name of the patient is identified in the first
column.For further information or to pass on comments, please contact Max
Little (littlem '@' robots.ox.ac.uk).

Further details are contained in the following reference -- if you use this
dataset, please cite:
Max A. Little, Patrick E. McSharry, Eric J. Hunter, Lorraine O. Ramig (2008),
'Suitability of dysphonia measurements for telemonitoring of Parkinson's disease',
IEEE Transactions on Biomedical Engineering (to appear).

##**Attribute Information:**

Matrix column entries (attributes):
name - ASCII subject name and recording number
MDVP:Fo(Hz) - Average vocal fundamental frequency

MDVP:Fhi(Hz) - Maximum vocal fundamental frequency

MDVP:Flo(Hz) - Minimum vocal fundamental frequency

MDVP:Jitter(%),MDVP:Jitter(Abs),MDVP:RAP,MDVP:PPQ,Jitter:DDP - Several
measures of variation in fundamental frequency

MDVP:Shimmer,MDVP:Shimmer(dB),Shimmer:APQ3,Shimmer:APQ5,MDVP:APQ,Shimmer:DDA - Several measures of variation in amplitude

NHR,HNR - Two measures of ratio of noise to tonal components in the voice
status
- Health status of the subject (one)
- Parkinson's, (zero)
- healthyRPDE,D2
- Two nonlinear dynamical complexity measures DFA
- Signal fractal scaling exponent
spread1,spread2,PPE
- Three nonlinear measures of fundamental frequency variation

Citation Request:

If you use this dataset, please cite the following paper:
'Exploiting Nonlinear Recurrence and Fractal Scaling Properties for Voice Disorder Detection',
Little MA, McSharry PE, Roberts SJ, Costello DAE, Moroz IM.
BioMedical Engineering OnLine 2007, 6:23 (26 June 2007)

#**Import the Libraries**
"""

## import some basic libraries
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn import svm
from sklearn.metrics import accuracy_score

"""#**Data Collection and Analysis**"""

# Loading the dataset into a pandas DataFrame
parkinsons_data = pd.read_csv('parkinsons.csv')

# Display the first few rows
print("First 5 rows of the dataset:")
parkinsons_data.head()

# Display the last few rows
print("Last 5 rows of the dataset:")
parkinsons_data.tail()

# Checking the shape of the dataset
parkinsons_data.shape    # Outputs the number of rows and columns in the dataset.

# Statistical description of the dataset
print("\nStatistical Description of the Dataset:")
parkinsons_data.describe()

# Check for missing values
missing_values = parkinsons_data.isnull().sum()
print("\nMissing values in each column:")
print(missing_values)

# Geerating some Information about the dataset
parkinsons_data.info()

# Checking the distribution of data
print("\nDistribution of Data:")
print(parkinsons_data.value_counts())

# Checking the distribution of Target Variable
print("\nDistribution of Data Target Variable:")
print(parkinsons_data["status"].value_counts())

"""* 1 ---> **147 People have Parkinsons Disease**
* 0 ---> **40  Healthy People (i.e Doesn't have Parkinsons)**

"""

# Grouping the data based on the target variable and calculating the mean of numeric columns only
parkinsons_data.groupby('status').mean(numeric_only=True)

"""# **Data Preprocessing**

**Splitting features and target**
"""

# Splitting features and target
X = parkinsons_data.drop(columns=['name', 'status'], axis=1)
y = parkinsons_data['status']

print("Features (X):")
print(X.head())
print("\nTarget (y):")
print(y.head())

"""# **Splitting the dataset into Training and Test sets**"""

# Splitting the dataset into Training and Test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=3)
print("\nDataset split completed:")
print(f"Total samples: {X.shape[0]}, Training samples: {X_train.shape[0]}, Test samples: {X_test.shape[0]}")

# checking the number of Test and Train dataset
print(X.shape, X_train.shape, X_test.shape)

"""#**Data Standardization**"""

# Standardize of data
scaler = StandardScaler()

# Fitting the data
scaler.fit(X_train)

X_train_transform = scaler.transform(X_train)

X_test_transform = scaler.transform(X_test)

print(X_train_transform)

"""# **Model Training**"""

# Initialize Support Vector Machine
model = svm.SVC(kernel='linear')

# Training the SVM model with train data
model.fit(X_train_transform, y_train)

"""#**Model Evaluation**"""

# Calculate accuracy on the training data
X_train_pred = model.predict(X_train_transform)
train_data_accuracy = accuracy_score(X_train_pred, y_train)
print('Accuracy on training data : ', train_data_accuracy)

# accuracy on the test data
X_test_pred = model.predict(X_test_transform)
test_data_accuracy = accuracy_score(X_test_pred, y_test)
print('Accuracy on test data : ', test_data_accuracy)

# Sample input data (new instance to classify)
input_data = [119.99200,157.30200,74.99700,0.00784,0.00007,0.00370,0.00554,0.01109,0.04374,0.42600,0.02182,0.03130,0.02971,0.06545,0.02211,21.03300,0.414783,0.815285,-4.813031,0.266482,2.301442,0.284654]

# Converting input data to a NumPy array
input_data_as_numpy_array = np.asarray(input_data)

# Reshaping the input array for prediction (to match model's expected input shape)
input_data_reshaped = input_data_as_numpy_array.reshape(1,-1)

# standardize the data
std_data = scaler.transform(input_data_reshaped)

# Making a prediction
prediction = model.predict(std_data)
print(prediction)

# Outputting the result
if prediction[0] == 0:
    print("The Person does not have Parkinsons Disease")
else:
    print("The Person have Parkinsons Disease")

# Sample input data (new instance to classify)
input_data = [197.07600,206.89600,192.05500,0.00289,0.00001,0.00166,0.00168,0.00498,0.01098,0.09700,0.00563,0.00680,0.00802,0.01689,0.00339,26.77500,0.422229,0.741367,-7.348300,0.177551,1.743867,0.085569]

# Converting input data to a NumPy array
input_data_as_numpy_array = np.asarray(input_data)

# Reshaping the input array for prediction (to match model's expected input shape)
input_data_reshaped = input_data_as_numpy_array.reshape(1,-1)

# standardize the data
std_data = scaler.transform(input_data_reshaped)

# Making a prediction
prediction = model.predict(std_data)
print(prediction)

# Outputting the result
if prediction[0] == 0:
    print("The Person does not have Parkinsons Disease")
else:
    print("The Person have Parkinsons Disease")